{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'dp'\n",
    "require 'hdf5'\n",
    "require 'optim'\n",
    "require 'gnuplot' --or 'image'\n",
    "\n",
    "path = '/Users/shima/Documents/MyQuarters/Quarter14/CS231n/final_project/CS231n/dataset/data.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function load_data(data_file)\n",
    "  local f = hdf5.open(data_file)\n",
    "  local dset = {}\n",
    "  dset.X_train = f:read('X_train'):all()\n",
    "  dset.y_train = f:read('y_train'):all() + 1\n",
    "  dset.X_val = f:read('X_val'):all()\n",
    "  dset.y_val = f:read('y_val'):all() + 1\n",
    "  dset.X_test = f:read('X_train'):all()\n",
    "  dset.y_test = f:read('y_train'):all() + 1\n",
    "  f:close()\n",
    "  print('Data is loaded, Ready to go!')\n",
    "  return dset\n",
    "end\n",
    "\n",
    "--[[ preprocess data before feeding that into the convnet\n",
    "     subtract mean of training data, and reshape it to the\n",
    "     form (N, 1, H, W) ]]--\n",
    "function preprocess_data(dset)\n",
    "\n",
    "    dset_new = {}\n",
    "\n",
    "    -- subtract mean\n",
    "\tmean_image = torch.mean(dset.X_train)\n",
    "\tdset_new.X_train = dset.X_train - mean_image\n",
    "\tdset_new.X_val = dset.X_val - mean_image\n",
    "\tdset_new.X_test = dset.X_test - mean_image\n",
    "\n",
    "\t-- reshape\n",
    "\tH = dset.X_train:size(2)\n",
    "\tW = dset.X_train:size(3)\n",
    "\t\n",
    "\tdset_new.X_train = torch.reshape(dset_new.X_train, dset.X_train:size(1), 1, H, W)\n",
    "\tdset_new.X_val = torch.reshape(dset_new.X_val, dset.X_val:size(1), 1, H, W)\n",
    "\tdset_new.X_test = torch.reshape(dset_new.X_test, dset.X_test:size(1), 1, H, W)\n",
    "\n",
    "    print('data preprocessing done.')\n",
    "\treturn dset_new\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data is loaded, Ready to go!\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "data preprocessing done.\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Now let's load the data\n",
    "local dset = load_data(path)\n",
    "dset = preprocess_data(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "--build a convnet model\n",
    "function full_conv_net(convlayer_params, affinelayer_params)\n",
    "  \n",
    "  local num_filters = convlayer_params['num_filters'] --{64,  64,  128,  128,  256, 256, 512, 512, 1024}\n",
    "  local filter_sizes =  convlayer_params['filter_size'] --{5,   3,   3,   3,   3,   3,   3,   3,   3}\n",
    "  local filter_strides = convlayer_params['stride'] --{2,   1,   2,   1,   2,   1,   2,   1,   2}\n",
    "  local zero_pad = convlayer_params['pad']\n",
    "  local use_sbatchnorm = convlayer_params['s_batch_norm']\n",
    "  local maxpool_dim = convlayer_params['pool_dim']\n",
    "  local maxpool_stride = convlayer_params['pool_stride']\n",
    "  \n",
    "  local hidden_dim = affinelayer_params['hidden_dim']\n",
    "  local use_batchnorm = affinelayer_params['batch_norm']\n",
    "  local use_dropout = affinelayer_params['dropout']\n",
    "    \n",
    "  local num_classes = 7\n",
    "  -- C: number of channels , H,W: height and width of an image\n",
    "  \n",
    "  local C, H, W = 1, 48, 48\n",
    "  next_H, next_W \n",
    "  local image_size = 48\n",
    "  local prev_dim = 3\n",
    "  local cur_size = image_size\n",
    "  \n",
    "  -- generate the model\n",
    "  local model = nn.Sequential()\n",
    "  for i = 1, #num_filters do\n",
    "        \n",
    "    local next_C = num_filters[i]\n",
    "    local size = filter_sizes[i]\n",
    "    local stride = filter_strides[i]\n",
    "    local pad = (size - 1) / 2\n",
    "    model:add(nn.SpatialConvolution(prev_dim, next_dim,\n",
    "              size, size, stride, stride, pad, pad))\n",
    "    model:add(nn.SpatialBatchNormalization(next_dim))\n",
    "    model:add(nn.ReLU(true))\n",
    "    model:add(nn.Dropout(dropout[i]))\n",
    "\n",
    "    prev_dim = next_dim\n",
    "    if stride == 2 then\n",
    "      cur_size = cur_size / 2\n",
    "    end\n",
    "  end\n",
    "\n",
    "  local fan_in = cur_size * cur_size * num_filters[#num_filters]\n",
    "  model:add(nn.View(-1):setNumInputDims(3))\n",
    "  model:add(nn.Linear(fan_in, hidden_dim))\n",
    "  model:add(nn.BatchNormalization(hidden_dim))\n",
    "  model:add(nn.Dropout(0.8))\n",
    "  model:add(nn.ReLU(true))\n",
    "  model:add(nn.Linear(hidden_dim, num_classes))\n",
    "\n",
    "  return model\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local convlayer_params = {'num_filters'= {32, 32}, 'filter_size'= {3, 3} ,'stride'={1, 1}, 'pad'=(3 - 1) / 2, \n",
    "                          's_batch_norm'= false, 'pool_dim'= 2, 'pool_stride'= 2}\n",
    "local affinelayer_params = {'hidden_dim'= {50}, 'batch_norm'= false,'dropout'= false}]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
